using NeuralEstimators
using CUDA
using LinearAlgebra
using Distributions
using Folds
using Statistics
using Test
using Random: seed!
import Base: rand

import NeuralEstimators: simulate

# ---- Priors ----

correlations_only = true

d = 3

# Non-Î£ parameters
Î© = (
	Î³ = Uniform(-0.3, 0.3),
	Ï‰ = Uniform(0.05, 1.0),
	Î» = Uniform(-1, 1)
)
parameter_names = String.(collect(keys(Î©)))

# Î£
struct CovarianceMatrixPrior
    Rprior
    Ïƒprior
end
function rand(cp::CovarianceMatrixPrior, K::Integer)
	R = rand(cp.Rprior, K)
    s = rand(cp.Ïƒprior, K)
    Î£ = map(1:K) do k
        S = Diagonal(s[:, k]) * R[k] * Diagonal(s[:, k])
        Symmetric(S)
    end
    Î£
end
Rprior = LKJ(d, 1.0) # prior over the correlation matrix
Ïƒprior = Product(repeat([Uniform(0.5, 2.0)], d)) # prior over the standard deviations
Î£prior = correlations_only ? Rprior : CovarianceMatrixPrior(Rprior, Ïƒprior)

# Insert Î£ parameters to Î©
Î© = merge(Î©, (Î£ = Î£prior,))
Î£_parameter_names = ["Î£$i$j" for i âˆˆ 1:d, j âˆˆ 1:d]
Î£_extraction_idx = tril(trues(d, d), correlations_only ? -1 : 0) # -1 indicates that we do not include the diagonal
parameter_names = vcat(parameter_names, Î£_parameter_names[Î£_extraction_idx])

# ---- Parameter configurations ----

Î¾ = (
	parameter_names = parameter_names,
	Î£idx = findall(occursin.("Î£", parameter_names)),
	nonÎ£idx = findall(.!occursin.("Î£", parameter_names)),
	Î£_extraction_idx = Î£_extraction_idx,
	Î© = Î©,
	p = length(parameter_names),
	d = d,
	correlations_only = correlations_only
)

# chol_pointer[i] gives the Cholesky factor associated with Î¸[:, i]
struct Parameters{T1, T2, I} <: ParameterConfigurations
	Î¸::Matrix{T1}
	chols::Array{T2, 3}
	chol_pointer::Vector{I}
	parameter_names
end

function Parameters(K::Integer, Î¾; J::Integer = 1)

	# Sample the non-Î£ parameters
	Î¸ = [rand(Ï‘, K * J) for Ï‘ in drop(Î¾.Î©, :Î£)]

	# Sample Î£
	Î£ = rand(Î¾.Î©.Î£, K)
	L = broadcast(x -> convert(Matrix, cholesky(Symmetric(x)).L), Î£)
	chols = stackarrays(L, merge = false)
	chol_pointer = repeat(1:K, inner = J) # pointer for parameter vector to corresponding Cholesky factor

	# Extract the parameters corresponding to Î£
	Î£_params = hcat([Î£[k][Î¾.Î£_extraction_idx] for k âˆˆ 1:K]...)
	Î£_params = repeat(Î£_params, inner = (1, J))

	# Concatenate into a matrix and convert to Float32 for efficiency
	Î¸ = hcat(Î¸...)'
	Î¸ = vcat(Î¸, Î£_params)
	Î¸ = Float32.(Î¸)

	Parameters(Î¸, chols, chol_pointer, Î¾.parameter_names)
end

# ---- Marginal simulation ----

function simulate(parameters::Parameters, m::R) where {R <: AbstractRange{I}} where I <: Integer

	K = size(parameters, 2)
	mÌƒ = rand(m, K)

	# Extract the parameters from Î¸, and the Cholesky factors
	Î¸ = parameters.Î¸
	T = eltype(Î¸)
	Î³ = Î¸[findfirst(parameters.parameter_names .== "Î³"), :]
	Î» = Î¸[findfirst(parameters.parameter_names .== "Î»"), :]
	Ï‰ = Î¸[findfirst(parameters.parameter_names .== "Ï‰"), :]
	chols = parameters.chols
	chol_pointer = parameters.chol_pointer

	Z = Folds.map(1:K) do k
		L = view(chols, :, :, chol_pointer[k])
		z = simulateGH(L, mÌƒ[k]; Î¼ = zero(T), Î³ = Î³[k], Î» = Î»[k], Ï‰ = Ï‰[k])
		z = Float32.(z)
		z
	end
	d = size(chols, 1)
	Z = reshape.(Z, d, 1, :) # extra dimension is needed to accomodate the encoding approach

	return Z
end
simulate(parameters::Parameters, m::Integer) = simulate(parameters, range(m, m))
simulate(parameters::Parameters) = stackarrays(simulate(parameters, 1))

# ---- Generalised-hyperbolic simulation ----

# Marginal simulation is easy, we just need to simulate from a Gaussian process
# and from a generalised inverse Gaussian (GIG) distribution.

function simulateGH(L::AbstractArray{T, 2}; Î¼, Î³, Î», Ï‰, Î· = 1) where T <: Number
	W = simulategaussianprocess(L)
	M = simulategig(Î» = Î», Ï‰ = Ï‰, Î· = Î·)
	Z = Î¼ .+ Î³ * M .+ sqrt(M) * W
	return Z
end

function simulateGH(L::AbstractArray{T, 2}, m::Integer; args...) where T <: Number
	n = size(L, 1)
	Z = similar(L, n, m)
	for h âˆˆ 1:m
		Z[:, h] = simulateGH(L; args...)
	end
	return Z
end

"""
	simulateconditionalGH(Z::Matrix{Union{Missing, T}, Î£::Matrix; Î³, Î¼, Î», Ï‰, Î·, H::Integer) where T
Conditional simulation from the generalised hyperbolic distribution, described
below.

The data Z should be a dÃ—n matrix of incompletely observed replicates.
The return type is a dÃ—n`H` matrix obtained by conditionally simulating `H`
times for each replicate (note that the order of replicates is not preserved).

# GH distribution

The d-dimensional random variable ğ™ is called a normal mean-variance mixture
(NMVM) if it can be represented as,

```math
ğ™ = ğ› + Mğ›„ + Mğ•
```

where ğ› âˆˆ â„áµˆ and ğ›„ âˆˆ â„áµˆ, and where M is a positive mixing random variable that
is independent of ğ• âˆ¼ Gau(ğŸ, ğšº) for covariance matrix ğšº. This flexible family of
distributions is closed under conditioning. With ğ™ = (ğ™â‚', ğ™â‚‚')' and with ğ›, ğ›„,
and ğšº partitioned accordingly, ğ™â‚‚ | ğ™â‚ is also a NMVM, with mixing variable
M | ğ™â‚ and parameters (Jamalizadeh and Balakrishnan, 2019, Thm. 1),

```math
ğ›â‚‚âˆ£â‚  = ğ›â‚‚ + ğšºâ‚‚â‚ğšºâ‚â‚â»Â¹(ğ™â‚âˆ’ğ›â‚),
ğ›„â‚‚|â‚  = ğ›„â‚‚ - ğšºâ‚‚â‚ğšºâ‚â‚â»Â¹ğ›„â‚,
ğšºâ‚‚â‚‚âˆ£â‚ = ğšºâ‚‚â‚‚ - ğšºâ‚‚â‚ğšºâ‚â‚â»Â¹ğšºâ‚â‚‚.
```

The generalised hyperbolic (GH) distribution (Barndorff-Nielsen, 1977) is
obtained when M follows a generalised inverse Gaussian (GIG) distribution.
If M âˆ¼ GIG(Ï‰, Î·, Î») with density function,

```math
f(m; Î», Î·, Ï‰) âˆ m^{Î»-1}e^{-Ï‰(Î·/m + m/Î·)/2}, 	m > 0,
```

then M | Zâ‚ also follows a GIG distribution with parameters
(Jamalizadeh and Balakrishnan, 2019, Cor. 2),

```math
Ï‰â‚‚âˆ£â‚ = [(q(ğ™â‚; ğ›â‚, ğšºâ‚â‚) + Ï‰Î·)(Ï‰/Î· + ğ›„â‚'ğšºâ‚â‚â»Â¹ğ›„â‚)]^{1/2},
Î·â‚‚âˆ£â‚ = [(q(ğ™â‚; ğ›â‚, ğšºâ‚â‚) + Ï‰Î·)/(Ï‰/Î· + ğ›„â‚'ğšºâ‚â‚â»Â¹ğ›„â‚)]^{1/2},
Î»â‚‚âˆ£â‚ = Î» âˆ’ dim(Zâ‚)/2,
```

where ``q(ğ™â‚; ğ›â‚, ğšºâ‚â‚) = (ğ™â‚âˆ’ğ›â‚)'ğšºâ‚â‚â»Â¹(ğ™â‚âˆ’ğ›â‚)``.

# Examples
```
d = 5
n = 1000
Z = rand(d, n)
Z = removedata(Z, 0.5)

Î¼ = randn(d)
Î³ = randn(d)
Î£ = randn(d, d); Î£ = Symmetric(0.5 * (Î£ + Î£')); Î£ = Î£ +  d * I(d)
Î» = randn(1)[1]
Ï‰ = rand(1)[1]
Î· = rand(1)[1]

simulateconditionalGH(Z, Î£; Î³ = Î³, Î» = Î», Ï‰ = Ï‰, Î· = Î·, Î¼ = Î¼, H = 10)
```
"""
function simulateconditionalGH(Z::Mâ‚, Î£::Mâ‚‚; Î³, Î¼, Î», Ï‰, Î·, H::Integer) where {Mâ‚ <: AbstractMatrix{Union{Missing, T}},  Mâ‚‚ <: AbstractMatrix} where T

  	# Dimension of the response and number of replicates
  	d  = size(Z, 1)
  	n  = size(Z, 2)

  	# Get the indices of the observed component for each replicate.
	idx = [findall(x -> !ismissing(x), vec(Z[:, i])) for i âˆˆ 1:n]

	# Handle replicates without any observations, and completely observed replicates
	unique_idx = unique(idx)
	@assert !any(length.(unique_idx) == 0) "dim(Zâ‚) = 0: cannot do conditional simulation without data to condition on" # NB could just simulate from the marginal in this case
	deleteat!(unique_idx, findall(Ref(1:d) .== unique_idx))

	# Consider groups of replicates with the same missingness pattern for computational efficiency
	W = map(unique_idx) do Iâ‚

    	# Missing elements
    	Iâ‚‚ = (1:d)[1:d .âˆ‰ Ref(Iâ‚)]

    	# Extract replicates with the missingness pattern Iâ‚
    	z =  Z[:, findall(Ref(Iâ‚) .== idx)]
		nÌƒ = size(z, 2)

		# Extract parameter subvectors and submatrices
		Î¼â‚ = Î¼[Iâ‚]
		Î¼â‚‚ = Î¼[Iâ‚‚]
		Î³â‚ = Î³[Iâ‚]
		Î³â‚‚ = Î³[Iâ‚‚]
		Î£â‚â‚ = Î£[Iâ‚, Iâ‚]
		Î£â‚‚â‚‚ = Î£[Iâ‚‚, Iâ‚‚]
		Î£â‚‚â‚ = Î£[Iâ‚‚, Iâ‚]
		Î£â‚â‚‚ = Î£[Iâ‚, Iâ‚‚]

		# Compute conditional parameters that do not depend on Zâ‚
		Lâ‚â‚ = try
			cholesky(Symmetric(Î£â‚â‚)).L
		catch
			@warn "Failed to compute the Cholesky factor of Î£â‚â‚: ignoring this batch of $nÌƒ out of $n total replicates"
			return missing
		end
		u = Lâ‚â‚ \ Î£â‚â‚‚   # Lâ‚â‚â»Â¹Î£â‚â‚‚
		w = Lâ‚â‚ \ Î³â‚    # Lâ‚â‚â»Â¹Î³â‚
		quadform_Î³Î³ = w'w
		Î»star   = Î» - length(Iâ‚)/2
		Î³â‚‚star  = Î³â‚‚ - u'w
		Î£â‚‚â‚‚star = Î£â‚‚â‚‚ - u'u
		Lâ‚‚â‚‚star = try
			cholesky(Symmetric(Î£â‚‚â‚‚star)).L
		catch
			@warn "Failed to compute the Cholesky factor of Î£â‚‚â‚‚âˆ£â‚: ignoring this batch of $nÌƒ out of $n total replicates"
			return missing
		end

		# Conditional simulation for each Zâ‚
		W = map(eachcol(z)) do Zâ‚

			# Extract the observed data and drop Missing from the eltype
			Zâ‚ = Zâ‚[Iâ‚]
			Zâ‚ = [Zâ‚...]

			# Compute conditional parameters that depend on Zâ‚
			v = Lâ‚â‚ \ (Zâ‚ - Î¼â‚) # Lâ‚â‚â»Â¹(Zâ‚ - Î¼â‚)
			Î¼â‚‚star  = Î¼â‚‚ + u'v
			quadform_zz = v'v
			Ï‰star = try
				sqrt( (Ï‰*Î· + quadform_zz) * (Ï‰/Î· + quadform_Î³Î³) )
			catch
				@warn "Computation of Ï‰â‚‚âˆ£â‚ failed: ignoring this batch of $nÌƒ out of $n total replicates"
				return missing
			end
			Î·star = try
				sqrt( (Ï‰*Î· + quadform_zz) / (Ï‰/Î· + quadform_Î³Î³) )
			catch
				@warn "Computation of Î·â‚‚âˆ£â‚ failed: ignoring this batch of $nÌƒ out of $n total replicates"
				return missing
			end

			# Simulate from the conditional distribution Zâ‚‚ âˆ£ Zâ‚, Î¸
			Zâ‚‚ = simulateGH(Lâ‚‚â‚‚star, H; Î¼ = Î¼â‚‚star, Î³ = Î³â‚‚star, Î» = Î»star, Ï‰ = Ï‰star, Î· = Î·star)

			# Combine the observed and missing data to form the complete data
			W = map(1:H) do h
				w = Vector{T}(undef, d)
				w[Iâ‚] = Zâ‚
				w[Iâ‚‚] = Zâ‚‚[:, h]
				w
			end
			hcat(W...) # d Ã— H Matrix{T}
		end
		W = skipmissing(W)
		W = hcat(W...) # d Ã— (náµ¢H) Matrix{T}, where náµ¢ is the number of replicates in the current batch
		if all(ismissing.(W)) W =  Matrix{T}(undef, d, 0) end # when all simulations fails
		W
	end
	W = skipmissing(W)
	W = hcat(W...) # d Ã— (nÌƒH) Matrix{T}, where nÌƒ is the total number of replicates excluding those replicates that are fully observed
  if all(ismissing.(W)) W =  Matrix{T}(undef, d, 0) end # when all simulations fails

	# Now add the completely observed replicates (if there are any)
	if any(idx .== Ref(1:d))
		z =  Z[:, findall(idx .== Ref(1:d))] # extract completely observed replicates
		w = repeat(z, inner = (1, H))        # repeat each replicate H times
		w = convert(Matrix{T}, w)            # drop Missing from the eltype
		W = hcat(W, w) # d Ã— (nH) Matrix{T}
	end

	return W # d Ã— (nH) Matrix{T}
end

function simulateconditionalGH(Z::V, Î£::Mâ‚‚; args...) where {V <: AbstractVector{Union{Missing, T}},  Mâ‚‚ <: AbstractMatrix} where T
	Z = reshape(Z, :, 1)
	simulateconditionalGH(Z, Î£; args...)
end



# ---- Generalised-hyperbolic density ----

function GHdensity(Z::A, Î£::M; args...) where {A <: Union{AbstractVector{T}, AbstractMatrix{T}}, M <: AbstractMatrix} where {T}
	L = cholesky(Symmetric(Î£)).L
	GHdensity(Z, L; args...)
end

function GHdensity(Z::M, L::LT; Î³, Î», Ï‰, Î·, Î¼ = repeat([zero(T)], length(Î³)), logdensity::Bool = true) where {M <: AbstractMatrix{Union{Missing, T}}, LT <: LowerTriangular} where {T}

	# Get the indices of the observed component for each replicate.
	m   = size(Z, 2)
	idx = [findall(x -> !ismissing(x), vec(Z[:, i])) for i âˆˆ 1:m]

	# This code caters for complete and incomplete data. Here, we drop any
	# missing observations from Z, and in the process convert the eltype of Z
	# from Union{Missing, x} to x, where x is some basic type (e.g., Float64).
	Z = [[Z[idx[i], i]...] for i âˆˆ 1:m]

	# Compute the density over groups of replicates with the same missingness pattern
	â„“ = map(unique(idx)) do Iâ‚
		 x = findall(Ref(Iâ‚) .== idx) # find all replicates with the same missingness pattern
		 z = hcat(Z[x]...)
		 Î¼star, Î³star, Î£star, Î»star, Ï‰star, Î·star = GHmarginalparameters(Iâ‚, Î¼, Î³, L, Î», Ï‰, Î·)
		 Lstar = cholesky(Î£star).L
		 GHdensity(z, Lstar; Î¼ = Î¼star, Î³ = Î³star, Î» = Î»star, Ï‰ = Ï‰star, Î· = Î·star, logdensity = logdensity)
	end
	â„“  = skipmissing(â„“)
	return logdensity ? sum(â„“) : prod(â„“)
end

# function GHdensity(Z::A, L::LT; logdensity::Bool = true, args...) where {A <: AbstractArray{T, N}, LT <: LowerTriangular} where {T, N}
function GHdensity(Z::A, L::LT; logdensity::Bool = true, args...) where {A <: Union{AbstractVector{T}, AbstractMatrix{T}}, LT <: LowerTriangular} where {T}
	â„“  = [GHdensity(z, L; logdensity = logdensity, args...) for z in eachcol(Z)]
	â„“  = skipmissing(â„“)
	return logdensity ? sum(â„“) : prod(â„“)
end

function GHdensity(z::V, L::LT; Î³, Î», Ï‰, Î·, Î¼ = repeat([zero(T)], length(Î³)), logdensity::Bool = true) where {V <: AbstractVector{T}, LT <: LowerTriangular} where T

	d = length(z)

	# Quadratic forms: uses the result u'Î£v = x'y where x = Lâ»Â¹u and y = Lâ»Â¹v.
	x = L \ (z - Î¼)  # solution to Lx = z-Î¼
	y = L \ Î³        # solution to Ly = Î³
	quadform_zz = dot(x, x)
	quadform_Î³Î³ = dot(y, y)
	quadform_zÎ³ = dot(x, y)
	sqrt_term = sqrt((Ï‰*Î· + quadform_zz) * (Ï‰/Î· + quadform_Î³Î³))
	bessel_term = besselk(Î» - d/2, sqrt_term)
	try
		â„“ = log(bessel_term) + quadform_zÎ³ - (d/2 - Î») * log(sqrt_term)
		â„“ += (d/2-Î») * log(Ï‰/Î· + quadform_Î³Î³) - ( (d/2)*log(2Ï€) + logdet(L) + Î» * log(Î·) + log(besselk(Î», Ï‰)) )
		return logdensity ? â„“ : exp(â„“)
	catch
		# Try to identify why the computation failed
		if sqrt_term > 10^6
			@warn "sqrt_term blew up: ignoring this replicate"
		elseif bessel_term < 0
			@warn "bessel_term < 0: ignoring this replicate"
		else
		  @warn "ignoring replicate for unknown reason"
		end
		return missing
	end
end

# Iâ‚ are the indices of the observed elements
function GHmarginalparameters(Iâ‚, Î¼, Î³, L::LowerTriangular, Î», Ï‰, Î·)

  r = length(Iâ‚)
	@assert r > 0 "Need to have at least one observed element: that is, need `length(Iâ‚) > 0`)"

	d = length(Î¼)
	Iâ‚‚ = (1:d)[1:d .âˆ‰ Ref(Iâ‚)]
	@assert d == length(Î³) == length(Î¼)
	@assert size(L) == (d, d)

	Î£ = L * L'

	if r == d
		return Î¼, Î³, Î£, Î», Ï‰, Î·
	else
		Î¼â‚  = Î¼[Iâ‚]
		Î³â‚  = Î³[Iâ‚]
		Î£â‚â‚ = Î£[Iâ‚, Iâ‚]
		return Î¼â‚, Î³â‚, Î£â‚â‚, Î», Ï‰, Î·
	end
end



# ---- Generalised Inverse Gaussian (GIG) ----

# This code was adapted from the following Distributions.jl pull request:
# https://github.com/JuliaStats/Distributions.jl/pull/1300/files

using Distributions
import Distributions: convert
import Base: rand

"""
	simulategig(n = 1; Ï‰, Î·, Î»)
Simulates `n` realisations of a generalized inverse Gaussian (GIG) random
variable with density,

```math
f(x; Î», Î·, Ï‰)  âˆ x^{Î»-1}e^{-Ï‰(Î·/x + x/Î·)/2}, x > 0,
```

for concentration parameter Ï‰ > 0, scale parameter Î· > 0, and shape
parameter Î» âˆˆ â„. Note that this is equivalent to the parameterisation,

```math
f(x; Î», Ï‡, Ïˆ)  âˆ x^{Î»-1}e^{-(Ï‡/x + Ïˆx)/2}
```

with Ï‡ = Ï‰Î· and Ïˆ = Ï‰/Î·. Note that the inverse parameterisation is Î· = âˆš{Ï‡/Ïˆ} and Ï‰ = âˆš{Ï‡Ïˆ}.

The sampling procedure is based on [HÃ¶rmann & Leydold (2014)](https://doi.org/10.1007/s11222-013-9387-3).

# Examples

```julia
Î» = 0.5
Ï‰ = 2.1
Î· = 3.5
simulategig(Î» = Î», Ï‰ = Ï‰, Î· = Î·)
simulategig(10, Î» = Î», Ï‰ = Ï‰, Î· = Î·)
```
"""
function simulategig(n::Integer; Î», Ï‰, Î·)
	Ïˆ = Ï‰/Î·
	Ï‡ = Ï‰ * Î·
	rand(GeneralisedInverseGaussian(Ïˆ, Ï‡, Î»), n)
end
function simulategig(; Î», Ï‰, Î·)
	Ïˆ = Ï‰/Î·
	Ï‡ = Ï‰ * Î·
	rand(GeneralisedInverseGaussian(Ïˆ, Ï‡, Î»))
end

struct GeneralisedInverseGaussian{T<:Real} <: ContinuousUnivariateDistribution
    Ïˆ::T
    Ï‡::T
    p::T #NB p âŸº Î»
    GeneralisedInverseGaussian{T}(Ïˆ::T, Ï‡::T, p::T) where T = new{T}(Ïˆ,Ï‡,p)
end

function GeneralisedInverseGaussian(Ïˆ::T,Ï‡::T,p::T) where {T<:Real}
    @assert Ïˆ > zero(Ïˆ) && Ï‡ > zero(Ï‡)
    return GeneralisedInverseGaussian{T}(Ïˆ,Ï‡,p)
end

GeneralisedInverseGaussian(Ïˆ::Real, Ï‡::Real, p::Real) = GeneralisedInverseGaussian(promote(Ïˆ,Ï‡,p)...)
GeneralisedInverseGaussian(Ïˆ::Integer, Ï‡::Integer, p::Integer) = GeneralisedInverseGaussian(float(Ïˆ), float(Ï‡), float(p))
function convert(::Type{GeneralisedInverseGaussian{T}}, Ïˆ::Real, Ï‡::Real, p::Real) where T<:Real
    GeneralisedInverseGaussian(T(Ïˆ),T(Ï‡),T(p))
end
function convert(::Type{GeneralisedInverseGaussian{T}}, d::GeneralisedInverseGaussian{S}) where {T <: Real, S<: Real}
    GeneralisedInverseGaussian(T(d.Ïˆ), T(d.Ï‡), T(d.p))
end
params(d::GeneralisedInverseGaussian) = (d.Ïˆ, d.Ï‡, d.p)
@inline partype(d::GeneralisedInverseGaussian{T}) where {T<:Real} = T

#### Sampling

# NB Added iteration limit in the while loops to prevent hanging when the
# parameters are extreme

rand(d::GeneralisedInverseGaussian, n::Int64) = [rand(d) for _ in 1:n]

function rand(d::GeneralisedInverseGaussian)
    (Ïˆ,Ï‡,p) = params(d)
    Ï‰ = sqrt(Ïˆ/Ï‡) # NB This is not the same Ï‰ as described above
    Î· = sqrt(Ïˆ*Ï‡) # NB This is not the same Î· as described above
    Î» = abs(p)
    if Î· > 1 || Î» > 1
        x = sample_unif_mode_shift(Î»,Î·)
    else
        Î·_bound = min(1/2, (2/3)*sqrt(1 - p))
        if Î· < 1 && Î· >= Î·_bound
            x = sample_unif_no_mode_shift(Î»,Î·)
        elseif Î· < Î·_bound && Î· > 0
            x = concave_sample(Î»,Î·)
        else
            throw(ArgumentError("None of the required conditions on the parameters are satisfied"))
        end
    end
    if p >= 0
        return x/Ï‰
    else
        return 1 / (Ï‰*x)
    end
end

#Sample the 2-parameter GIG distribution with parameters p and Î· using the Rejection method
#as described by HÃ¶rmann & Leydold (2014).
function concave_sample(p::Real, Î·::Real; max_iteration::Integer = 10000, verbose::Bool = false)

    Ïµ = typeof(Î·)(0.000001) # small positive constant to prevent log(<0)

    m = Î·/((1 - p) + sqrt((1 - p)^2 + Î·^2))
    x_naut = Î·/(1 - p)
    x_star = max(x_naut,2/Î·)
    k1 = g(m,p,Î·)
    A1 = k1 * x_naut
    k2 = 0
    A2 = 0
    if x_naut < 2/Î·
        k2 = exp(-Î·)
        if p > 0
            A2 = k2 * ((2/Î·)^p - x_naut^p) / p
        else
            y = 2/Î·^2
            if y < 0 y += Ïµ end
            A2 = k2 * log(y)
        end
    end
    k3 = x_star^(p-1)
    A3 = 2 * k3 * exp(-x_star * Î· / 2) / Î·
    A = A1 + A2 + A3

    iteration = 1
    while true

        u = rand(Uniform(0,1))
        v = rand(Uniform(0,1))*A
        h = Inf
        if v <= A1
            x = x_naut * v / A1
            h = k1
        elseif v <= A1 + A2
            v = v - A1
            if p > 0
                x = (x_naut^p + (v*p/k2))^(1/p)
            else
                x = Î·*exp(v * exp(Î·))
            end
            h = k2 * x^(p-1)
        else
            v = v - (A1 + A2)
            y = exp(-x_star * Î· / 2) - (v * Î·) / (2 * k3)
            if y < 0 y += Ïµ end
            x = -2 * log(y) / Î·
            h = k3 * exp(-x * Î· / 2)
        end
        if (u * h) <= g(x,p,Î·) || iteration == max_iteration
            iteration == max_iteration && verbose && @warn "GIG sampling reached max iteration: check results carefully"
            return x
        end
        iteration += 1
    end
end

#Sample the 2-parameter GIG distribution with parameters p and Î· using the
#Ratio-of-Uniforms without mode shift as described by HÃ¶rmann & Leydold (2014).
function sample_unif_no_mode_shift(p::Real,Î·::Real; max_iteration::Integer = 10000, verbose::Bool = false)
    m = Î·/((1 - p) + sqrt((1 - p)^2 + Î·^2))
    xâº= ((1 + p) + sqrt((1 + p)^2 + Î·^2))/Î·
    vâº= sqrt(g(m,p,Î·))
    uâº= xâº * sqrt(g(xâº,p,Î·))

    iteration = 1
    while true
        u = rand(Uniform(0,1))*uâº
        v = rand(Uniform(0,1))*vâº
        x = u/v
        if v^2 <= g(x,p,Î·) || iteration == max_iteration
            iteration == max_iteration && verbose && @warn "GIG sampling reached max iteration: check results carefully"
            return x
        end
        iteration += 1
    end
end

#Sample the 2-parameter GIG distribution with parameters p and Î· using the
#Ratio-of-Uniforms with mode shift as described by HÃ¶rmann & Leydold (2014) (originally from Dagpunar (1989)).
function sample_unif_mode_shift(p::Real, Î·::Real; max_iteration::Integer = 10000, verbose::Bool = false)
    m = (sqrt((p - 1)^2 + Î·^2) + (p-1)) / Î·
    a = -(2*(p+1)/Î·) - m
    b = (2*(p-1)/Î·) * m - 1
    p2 = b - (a^2)/3
    q = (2*a^3)/27 - (a*b/3) + m
    Ï• = acos(-(q/2) * sqrt(-27 / (p2^3)))
    xâ» = sqrt((-4/3)*p2)*cos(Ï•/3 + (4/3)*Ï€) - (a / 3)
    xâº = sqrt((-4/3)*p2)*cos(Ï•/3) - (a/3)
    vâº = sqrt(g(m,p,Î·))
    uâ» = (xâ» - m)*sqrt(g(xâ»,p,Î·))
    uâº = (xâº - m)*sqrt(g(xâº,p,Î·))

    iteration = 1
    while true
        u = rand(Uniform(0,1))*(uâº - uâ») + uâ»
        v = rand(Uniform(0,1))*vâº
        x = (u / v) + m
        if (x > 0 && v^2 <= g(x,p,Î·)) || iteration == max_iteration
            iteration == max_iteration && verbose && @warn "GIG sampling reached max iteration: check results carefully"
            return x
        end
        iteration += 1
    end
end

function g(x::Real,p::Real,Î·::Real)
    x^(p-1)*exp(-(Î·/2)*(x + (1/x)))
end



# ---- Conditional simulation ----

"""
Generic function for defining conditional simulation, used in the EM algorithm.

The user must provide a method:

	simulateconditional(Zâ‚::M, Î¸, Î¾; nsims::Integer = 1) where {M <: AbstractMatrix{Union{Missing, T}}} where T

The three positional arguments are:

- `Zâ‚`: the observed, incomplete data. The last dimension of `Zâ‚` contains the replicates; the other dimensions store the response variable.
- `Î¸`: vector of parameters used for conditional simulation.
- `Î¾`: invariant model information needed for simulation (e.g., distance matrices).

Note that `Î¾` does not necessarily need to be used by the simulation algorithm but,
for consistency, it must be included in the method definition. The argument
`nsims` controls the number of simulations.
"""
function simulateconditional end

function simulateconditional(Z::A, Î¸, Î¾; nsims::Integer = 1) where {A <: AbstractArray{Union{Missing, T}, N}} where {T, N}

	# Save the original dimensions
	dims = size(Z)

	# Convert to matrix and pass to the matrix method
	Z = simulateconditional(Flux.flatten(Z), Î¸, Î¾; nsims = nsims)

	# Convert Z to the correct dimensions
	Z = reshape(Z, dims[1:end-1]..., :)

	return Z
end

function simulateconditional(Z::V, Î¸, Î¾; nsims::Integer) where {V <: AbstractVector{Union{Missing, T}}} where T

	## Convert to matrix and pass to the matrix method
	Z = reshape(Z, (length(Z), 1))
	Z = simulateconditional(Z, Î¸, Î¾; nsims = nsims)

	return Z
end

"""

# Examples 

using LinearAlgebra

A = [4.0 -1.0 0.0; -1.0 4.0 -1.0; 0.0 -1.0 -0.01]
A_pd = make_positive_definite(A)
"""
function make_positive_definite(A::AbstractMatrix{T}; epsilon::T = 1e-10) where T <: Real
    # Ensure the matrix is symmetric
    A = (A + A') / 2

    # Perform Eigen decomposition
    eigen_decomp = eigen(A)
    
    # Find the minimum eigenvalue
    min_eigenvalue = minimum(eigen_decomp.values)
    
    # If the minimum eigenvalue is positive, the matrix is already positive definite
    if min_eigenvalue > epsilon
        return A
    end
    
    # Shift the eigenvalues to ensure all are positive
    shift = abs(min_eigenvalue) + epsilon
    A_shifted = A + shift * I
    
    return A_shifted
end


"""
Replicates are stored in the columns of `Z`
"""
function simulateconditional(Z::M, Î¸, Î¾; nsims::Integer) where {M <: AbstractMatrix{Union{Missing, T}}} where T

	Î¸ = Float64.(Î¸)

	# Extract the parameters from Î¸ using information in Î¾
	parameter_names = Î¾.parameter_names
	Î³ = Î¸[findfirst(parameter_names .== "Î³")]; Î³ = repeat([Î³], d)
	Î¼ = repeat([0], length(Î³))
	Î· = one(eltype(Î¸)) 
	Ï‰ = Î¸[findfirst(parameter_names .== "Ï‰")]
	Î» = Î¸[findfirst(parameter_names .== "Î»")]
	Î£ = vectotril(Î¸[Î¾.Î£idx]; strict = Î¾.correlations_only)
	Î£[diagind(Î£)] .= 1
	Î£ = Symmetric(Î£, :L)
	
	# Ensure positive definite matrix
	Î£ = make_positive_definite(Î£)

	# Remove any columns that contain only missing elements
	Z = Z[:, vec(mapslices(z -> !all(ismissing.(z)), Z, dims = 1))]

	# Conditional simulation
	simulateconditionalGH(Z, Î£; Î³ = Î³, Î¼ = Î¼, Î» = Î», Ï‰ = Ï‰, Î· = Î·, H = nsims)
end

@testset "simulateconditional" begin
	seed!(1)
	d = 3
  n = 2000
	Z = rand(d, n)
	Z = removedata(Z, 0.25)

	Î³ = randn(1)[1]
	Î£ = randn(d, d); Î£ = Symmetric(0.5 * (Î£ + Î£')); Î£ = Î£ +  d * I(d)
	if correlations_only
		D = Diagonal(1 ./ sqrt.(Î£[diagind(Î£)]))
		Î£ = Symmetric(D * Î£ *D)
	end
	Î» = randn(1)[1]
	Ï‰ = rand(1)[1]
	Î· = rand(1)[1]
	Î¸ = [Î³, Ï‰, Î·, Î£[tril(trues(Î¾.d, Î¾.d), correlations_only)]...]

    H = 7
	W = simulateconditional(Z, Î¸, Î¾; nsims = H)
	@test size(W) == (d, n*H)
end


